import logging
import os
import pathlib
from collections import defaultdict
from datetime import datetime

from utils.file_utils import save_dict_to_file
from utils.openflow_utils import copy_remove_msg_data

CURRENT_PATH = pathlib.Path().absolute()
logger = logging.getLogger(__name__)
logger.setLevel(level=logging.WARNING)


class FlowMonitor(object):

    def __init__(self, report_folder, watch_generated_flows, *args, **kwargs):
        super(FlowMonitor, self).__init__(*args, **kwargs)

        self.name = "flow_monitor"

        self.flows = defaultdict()

        self.statistics = defaultdict()

        self.report_folder = report_folder
        # If flows generated by this class is reported, It is used to test
        self.watch_generated_flows = watch_generated_flows
        self.report_path = os.path.join(CURRENT_PATH, "reports", self.report_folder)

        self.reset_statistics()
        if watch_generated_flows:
            logger.warning(
                f"{datetime.now()} - {self.name} - Generated_flows will be watched !!! All flows statistics will be saved.")

    def get_status(self):
        status = {"watch_generated_flows": self.watch_generated_flows,
                  "report_folder": self.report_folder,
                  "report_path": self.report_path
                  }
        return status
        # if self.watch_generated_flows:
        #    hub.spawn_after(5, self._save_statistics_periodically)

    def add_to_flow_list(self, dpid, flow_id, match, actions, priority, idle_timeout, hard_timeout):
        if self.watch_generated_flows:
            if dpid not in self.statistics["flows"]:
                self.statistics["flows"][dpid] = {}

            self.statistics["flows"][dpid][flow_id] = {"match": match,
                                                       "actions": actions,
                                                       "priority": priority,
                                                       "idle_timeout": idle_timeout,
                                                       "hard_timeout": hard_timeout,
                                                       "created": datetime.now().timestamp(),
                                                       "datapath_id": dpid
                                                       }
            self.statistics["created-flow-count"] = self.statistics["created-flow-count"] + 1

    def save_statistics(self):
        now = int(datetime.now().timestamp())
        file_name = "%s-controller-flow-stats.json" % now
        return save_dict_to_file(self.report_path, file_name, self.statistics)

    def get_statistics(self):
        return self.statistics

    def reset_statistics(self):
        self.statistics["flows"] = defaultdict()
        self.statistics["created-flow-count"] = 0
        self.statistics["removed-flow-count"] = 0

    def flow_removed_handler(self, ev):
        msg = ev.msg
        dp = msg.datapath
        parser = dp.ofproto_parser
        ofproto = dp.ofproto
        if dp.id in self.flows:
            if msg.cookie in self.flows[dp.id]:
                info = self.flows[dp.id][msg.cookie]
                callers = info["caller"]
                if callers:
                    for caller in callers:
                        caller.flow_removed(msg)
                group_id = info["group_id"]
                if group_id is not None:
                    delete_group = parser.OFPGroupMod(datapath=dp, command=ofproto.OFPGC_DELETE,
                                                      group_id=group_id)
                    dp.send_msg(delete_group)

                del self.flows[dp.id][msg.cookie]

        # if self.watch_generated_flows:
        if msg.datapath.id in self.statistics["flows"]:
            if msg.cookie in self.statistics["flows"][msg.datapath.id]:
                self.statistics["removed-flow-count"] = self.statistics["removed-flow-count"] + 1
                stats = self.statistics["flows"][msg.datapath.id][msg.cookie]
                copy_remove_msg_data(msg, stats)
